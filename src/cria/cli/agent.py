
import ollama
import json
from cli import tools
from cli.tui import display_agent_thought, display_observation, get_user_input
import inspect

MODEL = 'llama3.1:latest'
MAX_ITERATIONS = 10

def get_available_tools():
    """
    Returns a dictionary of available tools, mapping tool names to their functions.
    """
    return {
        "list_files": tools.list_files,
        "read_file": tools.read_file,
        "write_file": tools.write_file,
        "execute_command": tools.execute_command,
    }

def get_system_prompt():
    """
    Generates the system prompt for the AI agent, including tool definitions.
    """
    tool_definitions = ""
    for name, func in get_available_tools().items():
        tool_definitions += f"""- {name}:
"""
        tool_definitions += f"""  - Description: {inspect.getdoc(func)}
"""
        tool_definitions += f"""  - Arguments: {inspect.signature(func)}

"""

    return f"""
You are an expert AI programming assistant. Your goal is to help users with their coding tasks.

You will be given a user's goal and a series of observations. You must respond with a single JSON object representing your next action.

You have access to the following tools:
{tool_definitions}

Your response must be in this exact format:
{{
  "tool": "tool_name",
  "args": {{
    "param1": "value1",
    "param2": "value2"
  }}
}}

If you have enough information to answer the user's goal, use the "finish" tool:
{{
  "tool": "finish",
  "args": {{
    "response": "Your final answer here"
  }}
}}

**Important Rules:**
1.  **Always respond with a valid JSON object.** Do not include any other text, explanations, or apologies.
2.  **Only use the tools provided.** Do not invent new tools.
3.  **Pay close attention to the arguments for each tool.** Ensure you provide all required arguments with the correct names and types.
4.  **If a tool call fails, analyze the error message and try again.** Do not give up after a single failure.
5.  **If you are stuck, try to break down the problem into smaller steps.**

Let's begin!
"""

def get_initial_messages(goal):
    """
    Creates the initial message list with the system prompt and user goal.
    """
    return [
        {"role": "system", "content": get_system_prompt()},
        {"role": "user", "content": goal}
    ]

def get_next_action(messages):
    """
    Gets the next action from the LLM, ensuring it's a valid JSON object.
    """
    while True:
        try:
            response = ollama.chat(
                model=MODEL,
                messages=messages,
                options={"temperature": 0.1},
                format='json'
            )
            action = json.loads(response['message']['content'])
            return action
        except (json.JSONDecodeError, KeyError) as e:
            print(f"Error parsing model response: {e}. Retrying...")
            # Optionally, add the error to the messages to inform the model
            messages.append({"role": "assistant", "content": f"Invalid JSON response. Please provide a valid JSON object."})


def criticize_tool_call(action):
    """
    Criticizes the tool call generated by the model.
    Returns a string with criticism if the tool call is invalid, otherwise returns None.
    """
    tool_name = action.get("tool")
    tool_args = action.get("args", {})

    if not tool_name:
        return "The 'tool' field is missing in your response."

    if tool_name == "finish":
        if "response" not in tool_args:
            return "The 'response' field is missing in the 'finish' tool."
        return None

    available_tools = get_available_tools()
    if tool_name not in available_tools:
        return f"Unknown tool '{tool_name}'. Please choose from the available tools: {list(available_tools.keys())}"

    tool_function = available_tools[tool_name]
    try:
        # Check if all required arguments are present
        sig = inspect.signature(tool_function)
        for param in sig.parameters.values():
            if param.default == inspect.Parameter.empty and param.name not in tool_args:
                return f"Missing required argument '{param.name}' for tool '{tool_name}'."
        
        # Check for unexpected arguments
        for arg_name in tool_args:
            if arg_name not in sig.parameters:
                return f"Unexpected argument '{arg_name}' for tool '{tool_name}'."

        return None  # No criticism
    except Exception as e:
        return f"An unexpected error occurred during criticism: {e}"


def execute_tool(tool_name, tool_args):
    """
    Executes a tool and returns the observation.
    """
    available_tools = get_available_tools()
    tool_function = available_tools[tool_name]
    try:
        return tool_function(**tool_args)
    except Exception as e:
        return f"Error executing tool '{tool_name}': {e}"

def run_agent(goal):
    """
    The main agent loop.
    """
    messages = get_initial_messages(goal)
    
    for i in range(MAX_ITERATIONS):
        print(f"Iteration {i + 1}")
        
        action = get_next_action(messages)
        if not action:
            print("Could not get a valid action from the model. Aborting.")
            break

        display_agent_thought(action.get("tool", "N/A"), action.get("args", {}))

        criticism = criticize_tool_call(action)
        if criticism:
            display_observation(f"Criticism: {criticism}")
            messages.append({"role": "assistant", "content": json.dumps(action)})
            messages.append({"role": "user", "content": f"Your last tool call was invalid. {criticism}. Please try again."})
            continue

        if action["tool"] == "finish":
            display_observation(action["args"]["response"])
            break

        # User confirmation
        user_response = get_user_input("Execute this action? (y/n): ").lower()
        if user_response != 'y':
            print("Action cancelled by user.")
            break

        observation = execute_tool(action["tool"], action["args"])
        display_observation(observation)
        
        messages.append({"role": "assistant", "content": json.dumps(action)})
        messages.append({"role": "user", "content": f"Observation: {observation}"})

    else:
        print("Maximum iterations reached. Aborting.")
